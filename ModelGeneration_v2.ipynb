{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import glob, os\n",
    "import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_predict):\n",
    "  # Note this blows up if y_true = 0\n",
    "  # Ignore for demo -- in some sense an unsolvable\n",
    "  # problem with MAPE as an error metric\n",
    "  y_true = np.array(y_true)\n",
    "  y_predict = np.array(y_predict)\n",
    "  return np.abs((y_true - y_predict)/y_true).mean()\n",
    "\n",
    "def rmse(y_true, y_predict):\n",
    "  # Note this blows up if y_true = 0\n",
    "  # Ignore for demo -- in some sense an unsolvable\n",
    "  # problem with MAPE as an error metric\n",
    "  y_true = np.array(y_true)\n",
    "  y_predict = np.array(y_predict)\n",
    "  return np.sqrt(metrics.mean_squared_error(y_true, y_predict))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ComputeRegressions(odf, types, model):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    #model = GradientBoostingRegressor(max_depth=3, random_state=123, max_features = 'sqrt', subsample = 0.8, min_samples_split = 100)\n",
    "    #model = SVR(kernel='sigmoid')\n",
    "    mape_scorer = make_scorer(mape, greater_is_better=True)\n",
    "    rmse_scorer = make_scorer(rmse, greater_is_better=True)\n",
    "    result_dict = {}\n",
    "    for key, values in types.items():\n",
    "        X,y = odf[values].values, odf['target'].values\n",
    "        X = scaler.fit_transform(X)\n",
    "        y = minmax_scale(y)\n",
    "        y = y + 0.01\n",
    "        mape_scores = cross_val_score(model, X, y, scoring=mape_scorer, cv=cv, n_jobs=-1)\n",
    "        rmse_scores = cross_val_score(model, X, y, scoring=rmse_scorer, cv=cv, n_jobs=-1)\n",
    "\n",
    "        result_dict[key+'_mape'] = mape_scores.mean()\n",
    "        result_dict[key+'_rmse'] = rmse_scores.mean()\n",
    "    return result_dict\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ndf = {}\n",
    "k = 0\n",
    "#modelArray = [LinearRegression(), SVR(kernel='rbf'), SVR(kernel='poly'), SVR(kernel='linear'), RandomForestRegressor(max_depth=3), GradientBoostingRegressor(max_depth=3, random_state=123, max_features = 'sqrt', subsample = 0.8)]\n",
    "#modelName = ['Linear Regression','SVM (RBF)', 'SVM (Poly)','SVM(Linear)','Random Forest','Gradient Boost']\n",
    "\n",
    "modelArray = [LinearRegression(n_jobs=-1), \n",
    "              RandomForestRegressor(max_depth=3,n_jobs=-1), \n",
    "              GradientBoostingRegressor(max_depth=3, random_state=123, max_features = 'sqrt', subsample = 0.8),\n",
    "              SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1),\n",
    "              MLPRegressor(hidden_layer_sizes=(3), activation='tanh', solver='lbfgs', max_iter=1000)\n",
    "             ]\n",
    "modelName = ['Linear Regression','Random Forest','Gradient Boost', 'SVM', 'MLP']\n",
    "timestamps = [pd.Timestamp(2020, 3, 1),pd.Timestamp(2020, 7, 1),pd.Timestamp(2020, 10, 1)]\n",
    "wave = ['First','Second','Third', 'All']\n",
    "path = 'StateFiles'\n",
    "with os.scandir(path) as entries:\n",
    "    for entry in entries:\n",
    "        j=0\n",
    "        for model in modelArray:\n",
    "            for i in range(4):\n",
    "                row = {}\n",
    "                fname = entry.name\n",
    "                fips = fname.replace('CombinedDF_','').replace('.csv','')\n",
    "                #print(fips, modelName[j], wave[i])\n",
    "                df = pd.read_csv(path+'/'+fname)\n",
    "                df['target'] = df['cases_pc'].shift(-14)\n",
    "                df = df[df.notna()]\n",
    "                df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "                if i==2:\n",
    "                    df = df[df['date']>=timestamps[i]]\n",
    "                elif i<2:\n",
    "                    df = df[((df['date']>=timestamps[i]) & (df['date']<=timestamps[i+1]))]\n",
    "                else:\n",
    "                    df = df[df['date']>=timestamps[0]]\n",
    "                odf = df[df.columns[1:]].fillna(0)\n",
    "                odf = odf[odf['target']!=0]\n",
    "                #columns_ext = ['Ext_risk_c', 'cases_pc']\n",
    "                #columns_int = ['cases_pc']\n",
    "                columns_ext_int = ['Int_risk_c','Ext_risk_c', 'cases_pc']\n",
    "                columns_ext = ['Ext_risk_c', 'cases_pc']\n",
    "                columns_int = ['Int_risk_c','cases_pc']\n",
    "                columns_cas = ['cases_pc']\n",
    "                types = {'both':columns_ext_int, 'ext_only':columns_ext, 'int_only':columns_int, 'none':columns_cas}\n",
    "                row['fips'] = fips\n",
    "                result_dict = ComputeRegressions(odf, types, model)\n",
    "                row['Model'] = modelName[j]\n",
    "                row['Wave'] = wave[i]\n",
    "                for key, values in result_dict.items():\n",
    "                    row[key] = values\n",
    "                ndf[k] = row\n",
    "                k = k + 1\n",
    "            j = j + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame.from_dict(ndf, 'index')\n",
    "cdf.to_csv('completeAnalysis_Cases_INTEXT_10192021.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cdf_consolidated = cdf.groupby(['Model','Wave']).agg('mean').reset_index()\n",
    "cdf_consolidated.to_csv('CompleteAnalysis_Waves_Cases_INTEXT_10192021.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
