{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import glob, os\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def mape(y_true, y_predict):\n",
    "  # Note this blows up if y_true = 0\n",
    "  # Ignore for demo -- in some sense an unsolvable\n",
    "  # problem with MAPE as an error metric\n",
    "  y_true = np.array(y_true)\n",
    "  y_predict = np.array(y_predict)\n",
    "  return np.abs((y_true - y_predict)/y_true).mean()\n",
    "\n",
    "def rmse(y_true, y_predict):\n",
    "  # Note this blows up if y_true = 0\n",
    "  # Ignore for demo -- in some sense an unsolvable\n",
    "  # problem with MAPE as an error metric\n",
    "  y_true = np.array(y_true)\n",
    "  y_predict = np.array(y_predict)\n",
    "  return np.sqrt(metrics.mean_squared_error(y_true, y_predict))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def ComputeRegressions(odf, types, model):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "    #model = GradientBoostingRegressor(max_depth=3, random_state=123, max_features = 'sqrt', subsample = 0.8, min_samples_split = 100)\n",
    "    #model = SVR(kernel='sigmoid')\n",
    "    mape_scorer = make_scorer(mape, greater_is_better=True)\n",
    "    rmse_scorer = make_scorer(rmse, greater_is_better=True)\n",
    "    result_dict = {}\n",
    "    for key, values in types.items():\n",
    "        X,y = odf[values].values, odf['target'].values\n",
    "        X = scaler.fit_transform(X)\n",
    "        y = minmax_scale(y)\n",
    "        y = y + 0.01\n",
    "        #mape_scores = cross_val_score(model, X, y, scoring=mape_scorer, cv=cv, n_jobs=-1)\n",
    "        #rmse_scores = cross_val_score(model, X, y, scoring=rmse_scorer, cv=cv, n_jobs=-1)\n",
    "        \n",
    "        output = cross_validate(model, X, y, scoring='neg_mean_squared_error', \n",
    "                                cv= cv, n_jobs=1, return_estimator = True,\n",
    "                                return_train_score= True)\n",
    "        print(values, output['estimator'][0].coef_)\n",
    "        #result_dict[key+'_mape'] = mape_scores.mean()\n",
    "        #result_dict[key+'_rmse'] = rmse_scores.mean()\n",
    "    return result_dict\n",
    "        \n",
    "    \n",
    "    \n",
    "    '''X,y = odf[columns_int].values, odf['target'].values\n",
    "    X = scaler.fit_transform(X)\n",
    "    y = minmax_scale(y)\n",
    "    y = y + 0.01\n",
    "    mape_scores_int = cross_val_score(model, X, y, scoring=mape_scorer, cv=cv, n_jobs=-1)\n",
    "    rmse_scores_int = cross_val_score(model, X, y, scoring=rmse_scorer, cv=cv, n_jobs=-1)\n",
    "    return mape_scores_ext.mean(), rmse_scores_ext.mean(), mape_scores_int.mean(), rmse_scores_int.mean()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Int_risk_c', 'Ext_risk_c', 'cases_pc'] [-1.32687117 -0.01497804  1.63591284]\n",
      "['Ext_risk_c', 'cases_pc'] [-0.25783977  0.38621457]\n",
      "['Int_risk_c', 'cases_pc'] [-1.36531128  1.67059023]\n",
      "['cases_pc'] [0.33664201]\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "ndf = {}\n",
    "k = 0\n",
    "#modelArray = [LinearRegression(), SVR(kernel='rbf'), SVR(kernel='poly'), SVR(kernel='linear'), RandomForestRegressor(max_depth=3), GradientBoostingRegressor(max_depth=3, random_state=123, max_features = 'sqrt', subsample = 0.8)]\n",
    "#modelName = ['Linear Regression','SVM (RBF)', 'SVM (Poly)','SVM(Linear)','Random Forest','Gradient Boost']\n",
    "\n",
    "modelArray = [LinearRegression(n_jobs=-1), \n",
    "              RandomForestRegressor(max_depth=3,n_jobs=-1), \n",
    "              GradientBoostingRegressor(max_depth=3, random_state=123, max_features = 'sqrt', subsample = 0.8),\n",
    "              SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1),\n",
    "              MLPRegressor(hidden_layer_sizes=(3), activation='tanh', solver='lbfgs', max_iter=1000)\n",
    "             ]\n",
    "modelName = ['Linear Regression','Random Forest','Gradient Boost', 'SVM', 'MLP']\n",
    "timestamps = [pd.Timestamp(2020, 3, 1),pd.Timestamp(2020, 7, 1),pd.Timestamp(2020, 10, 1)]\n",
    "wave = ['First','Second','Third', 'All']\n",
    "path = '/Users/satyakatragadda/Documents/PythonProjects/Mobility_V3/StateFiles'\n",
    "with os.scandir(path) as entries:\n",
    "    for entry in entries:\n",
    "        j=0\n",
    "        for model in modelArray:\n",
    "            for i in range(4):\n",
    "                row = {}\n",
    "                fname = entry.name\n",
    "                fips = fname.replace('CombinedDF_','').replace('.csv','')\n",
    "                #print(fips, modelName[j], wave[i])\n",
    "                df = pd.read_csv(path+'/'+fname)\n",
    "                df['target'] = df['cases_pc'].shift(-14)\n",
    "                df = df[df.notna()]\n",
    "                df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "                if i==2:\n",
    "                    df = df[df['date']>=timestamps[i]]\n",
    "                elif i<2:\n",
    "                    df = df[((df['date']>=timestamps[i]) & (df['date']<=timestamps[i+1]))]\n",
    "                else:\n",
    "                    df = df[df['date']>=timestamps[0]]\n",
    "                odf = df[df.columns[1:]].fillna(0)\n",
    "                odf = odf[odf['target']!=0]\n",
    "                #columns_ext = ['Ext_risk_c', 'cases_pc']\n",
    "                #columns_int = ['cases_pc']\n",
    "                columns_ext_int = ['Int_risk_c','Ext_risk_c', 'cases_pc']\n",
    "                columns_ext = ['Ext_risk_c', 'cases_pc']\n",
    "                columns_int = ['Int_risk_c','cases_pc']\n",
    "                columns_cas = ['cases_pc']\n",
    "                types = {'both':columns_ext_int, 'ext_only':columns_ext, 'int_only':columns_int, 'none':columns_cas}\n",
    "                row['fips'] = fips\n",
    "                result_dict = ComputeRegressions(odf, types, model)\n",
    "                row['Model'] = modelName[j]\n",
    "                row['Wave'] = wave[i]\n",
    "                for key, values in result_dict.items():\n",
    "                    row[key] = values\n",
    "                ndf[k] = row\n",
    "                k = k + 1\n",
    "                break\n",
    "            j = j + 1\n",
    "            break\n",
    "        print(fips)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cdf = pd.DataFrame.from_dict(ndf, 'index')\n",
    "cdf.to_csv('completeAnalysis_Cases_INTEXT_10192021.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fips', 'Model', 'Wave', 'both_mape', 'both_rmse', 'ext_only_mape',\n",
       "       'ext_only_rmse', 'int_only_mape', 'int_only_rmse', 'none_mape',\n",
       "       'none_rmse'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cdf_consolidated = cdf.groupby(['Model','Wave']).agg('mean').reset_index()\n",
    "cdf_consolidated.to_csv('CompleteAnalysis_Waves_Cases_INTEXT_10192021.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
